{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import networkx as nx\n",
    "from functions import *\n",
    "import os\n",
    "import scipy as sp\n",
    "import scipy.io  \n",
    "import io\n",
    "import snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7th_graders',\n",
       " 'aves-weaver-social',\n",
       " 'bt.csv',\n",
       " 'contacts-prox-high-school-2013',\n",
       " 'contacts-prox-high-school-2013-attr',\n",
       " 'email_company',\n",
       " 'fb-messages',\n",
       " 'fb-pages-politician',\n",
       " 'fb-pages-tvshow',\n",
       " 'fb_friends.csv',\n",
       " 'high_tech_company',\n",
       " 'inf-euroroad',\n",
       " 'infect-dublin',\n",
       " 'infect-hyper',\n",
       " 'Karate',\n",
       " 'kidnappings',\n",
       " 'KKI',\n",
       " 'kor.2015.mers.1.00',\n",
       " 'law_firm',\n",
       " 'moreno_taro',\n",
       " 'physician_trust',\n",
       " 'primary-school-proximity',\n",
       " 'sgp.2003.sars.1.00',\n",
       " 'soc-firm-hi-tech',\n",
       " 'soc-hamsterster',\n",
       " 'swingers',\n",
       " 'uni_email',\n",
       " 'usa.2009.flu.1.00',\n",
       " 'usa.2020.covid.6.00',\n",
       " 'webkb-wisc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"less_than_1500_nodes\"\n",
    "[x.replace(\"{}\\\\\".format(path), \"\") for x in glob.glob(\"{}/*\".format(path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [x.replace(\"{}\\\\\".format(path), \"\") for x in glob.glob(\"{}/*\".format(path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th_graders\n",
      "aves-weaver-social\n",
      "bt.csv\n",
      "contacts-prox-high-school-2013\n",
      "contacts-prox-high-school-2013-attr\n",
      "email_company\n",
      "fb-messages\n",
      "fb-pages-politician\n",
      "fb-pages-tvshow\n",
      "fb_friends.csv\n",
      "high_tech_company\n",
      "inf-euroroad\n",
      "infect-dublin\n",
      "infect-hyper\n",
      "Karate\n",
      "kidnappings\n",
      "KKI\n",
      "kor.2015.mers.1.00\n",
      "law_firm\n",
      "moreno_taro\n",
      "physician_trust\n",
      "primary-school-proximity\n",
      "sgp.2003.sars.1.00\n",
      "soc-firm-hi-tech\n",
      "soc-hamsterster\n",
      "swingers\n",
      "uni_email\n",
      "usa.2009.flu.1.00\n",
      "usa.2020.covid.6.00\n",
      "webkb-wisc\n"
     ]
    }
   ],
   "source": [
    "G_list = []\n",
    "for d_path in data_paths:\n",
    "    print(d_path)\n",
    "    if any(fname.endswith('.csv') for fname in  glob.glob('{}/{}/*'.format(path,d_path))):\n",
    "        df = pd.read_csv('{}/{}/edges.csv'.format(path,d_path))\n",
    "        G = nx.from_pandas_edgelist(df, \"# source\", \" target\")\n",
    "        \n",
    "    elif any(fname.endswith('.edgelist') for fname in glob.glob('{}/{}/*'.format(path,d_path))):\n",
    "        G = nx.read_edgelist(\"{}/{}/edges.edgelist\".format(path, d_path), nodetype=int)\n",
    "        \n",
    "    elif not any(fname.endswith('txt.gz') for fname in  glob.glob('{}/{}/*'.format(path,d_path))):\n",
    "        G = nx.read_adjlist(\"{}/{}/edges.txt\".format(path, d_path), nodetype=int)\n",
    "\n",
    "    else:\n",
    "        G = nx.read_adjlist(gzip.open('{}/{}/edges.txt.gz'.format(path,d_path)), nodetype=int)\n",
    "            \n",
    "    G_list.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.graph.Graph at 0x1fdb953c070>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb854efd0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb953ce20>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb259f10>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb1d82b0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbae8b3d0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb9534c70>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb953c6a0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb953c760>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb24dfd0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb1d8280>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb953c0a0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbae8b310>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbae8b4c0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28dcd0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb0b0bb0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb9534dc0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb953c5e0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb953c040>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28dbe0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28daf0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdb9534460>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28dfd0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28d910>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28d970>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28df40>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28de20>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28de80>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28d8e0>,\n",
       " <networkx.classes.graph.Graph at 0x1fdbb28dac0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th_graders\n",
      "29\n",
      "aves-weaver-social\n",
      "445\n",
      "bt.csv\n",
      "692\n",
      "contacts-prox-high-school-2013\n",
      "327\n",
      "contacts-prox-high-school-2013-attr\n",
      "327\n",
      "email_company\n",
      "167\n",
      "fb-messages\n",
      "1899\n",
      "fb-pages-politician\n",
      "5908\n",
      "fb-pages-tvshow\n",
      "3892\n",
      "fb_friends.csv\n",
      "800\n",
      "high_tech_company\n",
      "21\n",
      "inf-euroroad\n",
      "1174\n",
      "infect-dublin\n",
      "410\n",
      "infect-hyper\n",
      "113\n",
      "Karate\n",
      "34\n",
      "kidnappings\n",
      "351\n",
      "kidnappings\n",
      "KKI\n",
      "2238\n",
      "kor.2015.mers.1.00\n",
      "186\n",
      "kor.2015.mers.1.00\n",
      "law_firm\n",
      "71\n",
      "moreno_taro\n",
      "22\n",
      "physician_trust\n",
      "241\n",
      "primary-school-proximity\n",
      "242\n",
      "sgp.2003.sars.1.00\n",
      "172\n",
      "sgp.2003.sars.1.00\n",
      "soc-firm-hi-tech\n",
      "33\n",
      "soc-hamsterster\n",
      "2426\n",
      "swingers\n",
      "96\n",
      "swingers\n",
      "uni_email\n",
      "1133\n",
      "usa.2009.flu.1.00\n",
      "286\n",
      "usa.2009.flu.1.00\n",
      "usa.2020.covid.6.00\n",
      "92\n",
      "usa.2020.covid.6.00\n",
      "webkb-wisc\n",
      "265\n",
      "Wall time: 14min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parameters \n",
    "nsamp = 10\n",
    "p = 0.05\n",
    "big_dat = pd.DataFrame({\"seeding method\": ['random']*nsamp + ['friend']*nsamp + ['pair']*nsamp})\n",
    "\n",
    "for i,G in enumerate(G_list):    \n",
    "    try:\n",
    "        print(data_paths[i])\n",
    "        print(nx.number_of_nodes(G_list[i]))\n",
    "\n",
    "        (rtran, ftran, ptran) = sim_2seed_transitivity(G_list[i], p = p, nsamp = nsamp)\n",
    "        # append results as columns\n",
    "        big_dat[\"{}_num_nodes:{}\".format(data_paths[i],  nx.number_of_nodes(G_list[i]))] = rtran + ftran + ptran\n",
    "    except:\n",
    "        print(data_paths[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dat.to_csv(\"2seedTransivityData1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th_graders\n",
      "aves-weaver-social\n",
      "bt.csv\n",
      "contacts-prox-high-school-2013\n",
      "contacts-prox-high-school-2013-attr\n",
      "email_company\n",
      "fb-messages\n",
      "fb-pages-politician\n",
      "fb-pages-tvshow\n",
      "fb_friends.csv\n",
      "high_tech_company\n",
      "inf-euroroad\n",
      "infect-dublin\n",
      "infect-hyper\n",
      "Karate\n",
      "kidnappings\n",
      "KKI\n",
      "kor.2015.mers.1.00\n",
      "BA\n",
      "law_firm\n",
      "moreno_taro\n",
      "physician_trust\n",
      "primary-school-proximity\n",
      "sgp.2003.sars.1.00\n",
      "BA\n",
      "soc-firm-hi-tech\n",
      "soc-hamsterster\n",
      "swingers\n",
      "uni_email\n",
      "usa.2009.flu.1.00\n",
      "BA\n",
      "usa.2020.covid.6.00\n",
      "BA\n",
      "webkb-wisc\n"
     ]
    }
   ],
   "source": [
    "G_random_BA = []\n",
    "G_random_configuration = []\n",
    "G_random_poisson = []\n",
    "\n",
    "for i, G_empirical in enumerate(G_list):\n",
    "\n",
    "    print(data_paths[i])\n",
    "\n",
    "    try:\n",
    "        G_BA = nx.barabasi_albert_graph(len(G_empirical.nodes()), int(np.average(G_empirical.degree())/2))\n",
    "        G_random_BA.append(G_BA)\n",
    "\n",
    "    except:\n",
    "        print(\"BA\")\n",
    "        G_random_BA.append(None)\n",
    "\n",
    "    try:\n",
    "        G_poisson =  nx.erdos_renyi_graph(len(G_empirical.nodes()), \n",
    "                                      np.mean(list(dict(G_empirical.degree()).values()))/(len(G_empirical.nodes()) - 1), seed = 2022)\n",
    "        largest_component = sorted(nx.connected_components(G_poisson), key=len, reverse=True)\n",
    "        G_poisson = G_poisson.subgraph(largest_component[0])\n",
    "        G_random_poisson.append(G_poisson)\n",
    "    except:\n",
    "        print(\"Poisson\")\n",
    "        G_random_poisson.append(None)\n",
    "\n",
    "    try:\n",
    "        G_config = nx.configuration_model(list(dict(G_empirical.degree()).values()), seed = 2022)\n",
    "        largest_component = sorted(nx.connected_components(G_config), key=len, reverse=True)\n",
    "        G_config = G_config.subgraph(largest_component[0])\n",
    "        G_random_configuration.append(G_config)\n",
    "    except:\n",
    "        print(\"Configuration\")\n",
    "        G_random_configuration.append(None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th_graders\n",
      "29\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "aves-weaver-social\n",
      "445\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "bt.csv\n",
      "692\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "contacts-prox-high-school-2013\n",
      "327\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "contacts-prox-high-school-2013-attr\n",
      "327\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "email_company\n",
      "167\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "fb-messages\n",
      "1899\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "fb-pages-politician\n",
      "fb-pages-tvshow\n",
      "fb_friends.csv\n",
      "800\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "high_tech_company\n",
      "21\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "inf-euroroad\n",
      "1174\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "infect-dublin\n",
      "410\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "infect-hyper\n",
      "113\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "Karate\n",
      "34\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "kidnappings\n",
      "351\n",
      "BA\n",
      "Configuration\n",
      "Failed\n",
      "Poisson\n",
      "KKI\n",
      "2238\n",
      "BA\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parameters \n",
    "nsamp = 10\n",
    "p = 0.05\n",
    "big_dat_random_BA = pd.DataFrame({\"seeding method\": ['random']*nsamp + ['friend']*nsamp + ['pair']*nsamp})\n",
    "big_dat_random_configuration = pd.DataFrame({\"seeding method\": ['random']*nsamp + ['friend']*nsamp + ['pair']*nsamp})\n",
    "big_dat_random_poisson = pd.DataFrame({\"seeding method\": ['random']*nsamp + ['friend']*nsamp + ['pair']*nsamp})\n",
    "\n",
    "for i,G in enumerate(G_random_BA): \n",
    "    \n",
    "    print(data_paths[i])\n",
    "    \n",
    "    if len(G_list[i].nodes()) < 3500:\n",
    "        print(nx.number_of_nodes(G_list[i]))\n",
    "    \n",
    "        try:\n",
    "            print(\"BA\")\n",
    "            (rtran, ftran, ptran) = sim_2seed_transitivity(G_random_BA[i], p = p, nsamp = nsamp)\n",
    "            big_dat_random_BA[\"{}_num_nodes:{}\".format(data_paths[i],  nx.number_of_nodes(G_random_BA[i]))] = rtran + ftran + ptran\n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "        try:\n",
    "            print(\"Configuration\")\n",
    "            (rtran, ftran, ptran) = sim_2seed_transitivity(G_random_configuration[i], p = p, nsamp = nsamp)\n",
    "            big_dat_random_configuration[\"{}_num_nodes:{}\".format(data_paths[i],  nx.number_of_nodes(G_random_configuration[i]))] = rtran + ftran + ptran\n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "        try:\n",
    "            print(\"Poisson\")\n",
    "            (rtran, ftran, ptran) = sim_2seed_transitivity(G_random_poisson[i], p = p, nsamp = nsamp)\n",
    "            big_dat_random_poisson[\"{}_num_nodes:{}\".format(data_paths[i],  nx.number_of_nodes(G_random_poisson[i]))] = rtran + ftran + ptran\n",
    "        except:\n",
    "            print(\"Failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dat_random.to_csv(\"2seedTransivityDataRandom1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Clustering Coefficients of Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individualClustering_empirical = [nx.clustering(G) for G in G_list]\n",
    "# individualClustering_random = [nx.clustering(G) if G is not None else None for G in G_random]\n",
    "\n",
    "\n",
    "averageClustering_empirical = [np.mean(list(G.values())) for G in individualClustering_empirical]\n",
    "averageClustering_random = [np.mean(list(G.values())) if G is not None else None for G in individualClustering_random]\n",
    "\n",
    "sdClustering_empirical = [np.std(list(G.values())) for G in individualClustering_empirical]\n",
    "sdClustering_random = [np.std(list(G.values())) if G is not None else None for G in individualClustering_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteringData = pd.DataFrame([data_paths, \n",
    "                               averageClustering_empirical, \n",
    "                               averageClustering_random,\n",
    "                               sdClustering_empirical,\n",
    "                               sdClustering_random]).transpose()\n",
    "clusteringData.columns = [\"network\", \"empirical_clust\", \"random_clust\", \"empirical_clustSD\", \"random_clustSD\"]\n",
    "clusteringData\n",
    "clusteringData.to_csv(\"clusteringData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4727556472565547,\n",
       " 0.31565787484542834,\n",
       " 0.4256024565776378,\n",
       " 0.35155732423906255,\n",
       " 0.35401488059421243,\n",
       " 0.3965018174550641,\n",
       " 0.314639725201374,\n",
       " 0.3118757159226849,\n",
       " 0.31222487932712867,\n",
       " 0.3186501413354587,\n",
       " 0.5170087226809915,\n",
       " 0.3118680844264864,\n",
       " 0.32490110882890133,\n",
       " 0.4286979767717517,\n",
       " 0.38758350453852186,\n",
       " 0.3087857124263623,\n",
       " 0.3119081551447534,\n",
       " None,\n",
       " 0.4107647383425519,\n",
       " 0.3019250951069133,\n",
       " 0.3358348440665224,\n",
       " 0.41548201320908923,\n",
       " None,\n",
       " 0.44319660543978023,\n",
       " 0.31352861391943665,\n",
       " 0.32859659478054476,\n",
       " 0.31404789759034185,\n",
       " None,\n",
       " None,\n",
       " 0.31600445878076827]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averageClustering_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766783097534905"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7766783097534905,\n",
       " 0.6685047954844804,\n",
       " 0.5251012948583238,\n",
       " 0.5035048191728448,\n",
       " 0.5035048191728448,\n",
       " 0.591863208548695,\n",
       " 0.10939892385364362,\n",
       " 0.38509612579327435,\n",
       " 0.37373843245973964,\n",
       " 0.3153509697401213,\n",
       " 0.8032036811780289,\n",
       " 0.016731564857629593,\n",
       " 0.45582424184357156,\n",
       " 0.5347555956050045,\n",
       " 0.5409685086155674,\n",
       " 0.0,\n",
       " 0.3872007143917601,\n",
       " 0.0,\n",
       " 0.5715333938756393,\n",
       " 0.33939393939393936,\n",
       " 0.3115751356464073,\n",
       " 0.5255415410620273,\n",
       " 0.0,\n",
       " 0.6705116697267809,\n",
       " 0.5375333362074076,\n",
       " 0.0,\n",
       " 0.22017608650411602,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2080282179610873]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averageClustering_empirical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
